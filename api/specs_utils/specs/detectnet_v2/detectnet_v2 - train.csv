parameter,display_name,value_type,description,default_value,examples,valid_min,valid_max,valid_options,required,popular,regex,automl_enabled,math_cond,parent_param,depends_on
gpus,number of gpus,integer,,1,,,,,,,,FALSE,,,
use_amp,,bool,,FALSE,,,,,,,,FALSE,,,
version,Schema Version,const,The version of this schema,1,,,,,,,,FALSE,,,
random_seed,Random Seed,integer,Seed value for the random number generator in the network,42,,,,,,,,FALSE,,,
dataset_config,Dataset,collection,Parameters to configure the dataset,,,,,,,,,FALSE,,,
dataset_config.image_extension,Image Extension,string,Extension of the images to be used.,png,,,,"png,jpg,jpeg",yes,,,FALSE,,,
dataset_config.data_sources.tfrecords_path,TFRecord Path,hidden,,,/shared/users/1234/datasets/5678/tfrecords/kitti_trainval/*,,,,,,,FALSE,,,
dataset_config.data_sources.image_directory_path,Image Path,hidden,,,/shared/users/1234/datasets/5678/training,,,,,,,FALSE,,,
dataset_config.validation_data_source.tfrecords_path,Validation TFRecord Path,hidden,,,/shared/users/1234/datasets/5678/tfrecords/kitti_trainval/*,,,,,,,FALSE,,,
dataset_config.validation_data_source.image_directory_path,Validation Image Path,hidden,,,/shared/users/1234/datasets/5678/training,,,,,,,FALSE,,,
dataset_config.target_class_mapping,Target Class Mappings,list,"This parameter maps the class names in the tfrecords to the target class to be trained in the network. An element is defined for every source class to target class mapping. This field was included with the intention of grouping similar class objects under one umbrella. For example: car,van,heavy_truck etc may be grouped under automobile.",,,,,,,,,FALSE,,,
dataset_config.target_class_mapping.key,Class Key,string,"The ""key"" field is the value of the class name in the tfrecords file.",person,,,,,,,"^[-a-zA-Z0-9_]{1,40}$",FALSE,,,
dataset_config.target_class_mapping.value,Class Value,string,"The ""value"" field corresponds to the value that the network is expected to learn.",person,,,,,,,"^[-a-zA-Z0-9_]{1,40}$",FALSE,,,
dataset_config.validation_fold,Validation Fold,integer,"In case of an n fold tfrecords,you define the index of the fold to use for validation. For sequencewise validation choose the validation fold in the range [0,N-1]. For random split partitioning,force the validation fold index to 0 as the tfrecord is just 2-fold.",,,0,,,,,,FALSE,,,
augmentation_config,Data Augmentation,collection,Collection of parameters to configure the preprocessing and on the fly data augmentation,,,,,,,Yes,,FALSE,,,
augmentation_config.preprocessing.output_image_width,Image Width,integer,The width of the augmentation output. This is the same as the width of the network input and must be a multiple of 16.,1280,,480,inf,,yes,Yes,,,/ 32,,
augmentation_config.preprocessing.output_image_height,Image Height,integer,The height of the augmentation output. This is the same as the height of the network input and must be a multiple of 16.,720,,272,inf,,yes,Yes,,,/ 32,,
augmentation_config.preprocessing.min_bbox_width,Bounding Box Width,float,The minimum width of the object labels to be considered for training.,1,,0,inf,,yes,,,FALSE,,,
augmentation_config.preprocessing.min_bbox_height,Bounding Box Height,float,The minimum height of the object labels to be considered for training.,1,,0,inf,,yes,,,FALSE,,,
augmentation_config.preprocessing.output_image_channel,Image Channel,integer,"The channel depth of the augmentation output. This is the same as the channel depth of the network input. Currently,1-channel input is not recommended for datasets with JPG images. For PNG images,both 3-channel RGB and 1-channel monochrome images are supported.",3,,,,"1,3",yes,,,FALSE,,,
augmentation_config.preprocessing.crop_right,Crop Right,integer,The right boundary of the crop to be extracted from the original image.,,,0,,,no,,,FALSE,,,
augmentation_config.preprocessing.crop_left,Crop Left,integer,The left boundary of the crop to be extracted from the original image.,,,0,,,no,,,FALSE,,,
augmentation_config.preprocessing.crop_top,Crop Top,integer,The top boundary of the crop to be extracted from the original image.,,,0,,,no,,,FALSE,,,
augmentation_config.preprocessing.crop_bottom,Crop Bottom,integer,The bottom boundary of the crop to be extracted from the original image.,,,0,,,no,,,FALSE,,,
augmentation_config.preprocessing.scale_height,Scale Height,float,The floating point factor to scale the height of the cropped images.,,,0,,,no,,,FALSE,,,
augmentation_config.preprocessing.scale_width,Scale Width,float,The floating point factor to scale the width of the cropped images.,,,0,,,no,,,FALSE,,,
augmentation_config.spatial_augmentation.hflip_probability,Horizontal-Flip Probability,float,The probability to flip an input image horizontally.,0.5,,0,1,,,,,,,,
augmentation_config.spatial_augmentation.vflip_probability,Vertical-Flip Probability,float,The probability to flip an input image vertically.,,,0,1,,,,,,,,
augmentation_config.spatial_augmentation.zoom_min,Minimum Zoom Scale,float,The minimum zoom scale of the input image.,1,,0,inf,,,,,,,,<= augmentation_config.spatial_augmentation.zoom_max
augmentation_config.spatial_augmentation.zoom_max,Maximum Zoom Scale,float,The maximum zoom scale of the input image.,1,,0,inf,,,,,,,TRUE,
augmentation_config.spatial_augmentation.translate_max_x,X-Axis Maximum Traslation,float,The maximum translation to be added across the x axis.,8,,0,,,,,,FALSE,,,
augmentation_config.spatial_augmentation.translate_max_y,Y-Axis Maximum Translation,float,The maximum translation to be added across the y axis.,8,,0,,,,,,FALSE,,,
augmentation_config.spatial_augmentation.rotate_rad_max,Image Rotation,float,"The angle of rotation to be applied to the images and the training labels. The range is defined between [-rotate_rad_max,rotate_rad_max].",,,0,,,,,,FALSE,,,
augmentation_config.color_augmentation.color_shift_stddev,Color Shift Standard Deviation,float,The standard devidation value for the color shift.,,,0,1,,,,,,,,
augmentation_config.color_augmentation.hue_rotation_max,Hue Maximum Rotation,float,The maximum rotation angle for the hue rotation matrix.,25,,0,360,,,,,,,,
augmentation_config.color_augmentation.saturation_shift_max,Saturation Maximum Shift,float,The maximum shift that changes the saturation. A value of 1.0 means no change in saturation shift.,0.2,,0,1,,,,,,,,
augmentation_config.color_augmentation.contrast_scale_max,Contrast Maximum Scale,float,The slope of the contrast as rotated around the provided center. A value of 0.0 leaves the contrast unchanged.,0.1,,0,1,,,,,,,,
augmentation_config.color_augmentation.contrast_center,Contrast Center,float,"The center around which the contrast is rotated. Ideally,this is set to half of the maximum pixel value. Since our input images are scaled between 0 and 1.0,you can set this value to 0.5.",0.5,,0,1,0.5,,,,,,,
bbox_rasterizer_config,Bounding box rasterizer,collection,Collection of parameters to configure the bounding box rasterizer,,,,,,,,,FALSE,,,
bbox_rasterizer_config.deadzone_radius,Bounding box rasterizer deadzone radius,float,,0.4,,0,1,,yes,,,,,,
model_config,Model,collection,,,,,,,,,,FALSE,,,
model_config.arch,BackBone Architecture,string,The architecture of the backbone feature extractor to be used for training.,resnet,,,,resnet,yes,,,FALSE,,,
model_config.pretrained_model_file,PTM File Path,hidden,"This parameter defines the path to a pretrained TLT model file. If the load_graph flag is set to false,it is assumed that only the weights of the pretrained model file is to be used. In this case,TLT train constructs the feature extractor graph in the experiment and loads the weights from the pretrained model file that has matching layer names. Thus,transfer learning across different resolutions and domains are supported. For layers that may be absent in the pretrained model,the tool initializes them with random weights and skips the import for that layer.",,/shared/.pretrained/resnet18/detectnet_v2_vresnet18/resnet18.hdf5,,,,,,,FALSE,,,
model_config.load_graph,PTM Load Graph,bool,"A flag to determine whether or not to load the graph from the pretrained model file,or just the weights. For a pruned model,set this parameter to True. Pruning modifies the original graph,so the pruned model graph and the weights need to be imported.",FALSE,,,,,,,,FALSE,,,
model_config.freeze_blocks,Freeze Blocks,integer,"This parameter defines which blocks may be frozen from the instantiated feature extractor template,and is different for different feature extractor templates.",,,0,3,,,,,,,,
model_config.freeze_bn,Freeze Batch Normalization,bool,A flag to determine whether to freeze the Batch Normalization layers in the model during training.,,,,,,,,,,,,
model_config.all_projections,All Projections,bool,"For templates with shortcut connections,this parameter defines whether or not all shortcuts should be instantiated with 1x1 projection layers,irrespective of whether there is a change in stride across the input and output.",,,,,,,,,,,,
model_config.num_layers,Number of Layers,ordered_int,The depth of the feature extractor for scalable templates.,18,,,,"10,18,34,50,101",yes,,,FALSE,,,
model_config.use_pooling,Use Pooling,bool,"Choose between using strided convolutions or MaxPooling while downsampling. When True,MaxPooling is used to downsample; however,for the object-detection network,NVIDIA recommends setting this to False and using strided convolutions.",,,,,,,,,,,,
model_config.use_batch_norm,Use Batch Normalization,bool,A flag to determine whether to use Batch Normalization layers or not.,TRUE,,,,,,,,,,,
model_config.dropout_rate,Dropout Rate,float,Probability for drop out,,,0,1,,,,,,,,
model_config.training_precision.backend_floatx,Backend Training Precision,string,A nested parameter that sets the precision of the backend training framework.,,,,,__FLOAT32__,no,,,FALSE,,,
model_config.objective_set.cov,Objective COV,collection,"The objectives for training the network. For object-detection networks,set it to learn cov and bbox. These parameters should not be altered for the current training pipeline.",{},,,,,yes,,,FALSE,,,
model_config.objective_set.bbox.scale,Objective Bounding Box Scale,float,"The objectives for training the network. For object-detection networks,set it to learn cov and bbox. These parameters should not be altered for the current training pipeline.",35,,,,,yes,,,FALSE,,,
model_config.objective_set.bbox.offset,Objective Bounding Box Offset,float,"The objectives for training the network. For object-detection networks,set it to learn cov and bbox. These parameters should not be altered for the current training pipeline.",0.5,,,,,yes,,,FALSE,,,
training_config,Training,collection,,,,,,,,,,FALSE,,,
training_config.batch_size_per_gpu,Batch Size Per GPU,integer,The number of images per batch per GPU.,4,,1,32,,yes,,,,,,
training_config.num_epochs,Number of Epochs,integer,The total number of epochs to run the experiment.,10,,1,500,,yes,Yes,,FALSE,,,
training_config.enable_qat,Enable Quantization Aware Training,bool,bool,FALSE,,,,,yes,Yes,,FALSE,,,
training_config.learning_rate,Learning rate during Training,collection,,,,,,,,,,FALSE,,,
training_config.learning_rate.soft_start_annealing_schedule,Soft start annealing schedule Learning rate type,collection,,,,,,,,,,FALSE,,,
training_config.learning_rate.soft_start_annealing_schedule.min_learning_rate,Minimum Learning Rate,float,The minimum learning rate in the learning rate schedule.,5.00E-06,,0,1,,yes,Yes,,TRUE,,,< training_config.learning_rate.soft_start_annealing_schedule.max_learning_rate
training_config.learning_rate.soft_start_annealing_schedule.max_learning_rate,Maximum Learning Rate,float,The maximum learning rate in the learning rate schedule.,5.00E-04,,0,1,,yes,Yes,,,,TRUE,
training_config.learning_rate.soft_start_annealing_schedule.soft_start,Soft Start,float,The time to ramp up the learning rate from minimum learning rate to maximum learning rate.,0.100000001,,0,1,,yes,Yes,,TRUE,,,< training_config.learning_rate.soft_start_annealing_schedule.annealing
training_config.learning_rate.soft_start_annealing_schedule.annealing,Annealing,float,The time to cool down the learning rate from maximum learning rate to minimum learning rate. Greater than soft_start.,0.699999988,,0,1,,yes,Yes,,TRUE,,TRUE,
training_config.learning_rate.early_stopping_annealing_schedule,Early stopping annealing schedule Learning rate type,collection,,,,,,,,,,FALSE,,,
training_config.learning_rate.early_stopping_annealing_schedule.min_learning_rate,Minimum Learning Rate,float,The minimum learning rate in the learning rate schedule.,,,0,1,,yes,Yes,,,,,< training_config.learning_rate.early_stopping_annealing_schedule.max_learning_rate
training_config.learning_rate.early_stopping_annealing_schedule.max_learning_rate,Maximum Learning Rate,float,The maximum learning rate in the learning rate schedule.,,,0,1,,yes,Yes,,,,TRUE,
training_config.learning_rate.early_stopping_annealing_schedule.soft_start_epochs,Soft Start epoch number,int,The time to ramp up the learning rate from minimum learning rate to maximum learning rate.,,,1,9,,yes,Yes,,,,,< training_config.learning_rate.early_stopping_annealing_schedule.annealing_epochs
training_config.learning_rate.early_stopping_annealing_schedule.annealing_epochs,Annealing epoch number,int,The time to cool down the learning rate from maximum learning rate to minimum learning rate. Greater than soft_start.,,,1,27,,yes,Yes,,,,TRUE,
training_config.regularizer.type,Regularizer Type,ordered,The type of the regularizer being used.,__L1__,,,,"__NO_REG__,__L1__,__L2__",yes,,,TRUE,,,
training_config.regularizer.weight,Regularizer Weight,float,The floating point weight of the regularizer.,3.00E-09,,3.00E-11,3.00E-03,,yes,,,,,,
training_config.optimizer.adam.epsilon,Optimizer Adam Epsilon,float,A very small number to prevent any division by zero in the implementation.,1.00E-08,,,,,yes,,,FALSE,,,
training_config.optimizer.adam.beta1,Optimizer Adam Beta1,float,,0.899999976,,0.5,0.95,,yes,,,,,,
training_config.optimizer.adam.beta2,Optimizer Adam Beta2,float,,0.999000013,,0.5,0.95,,yes,,,,,,
training_config.cost_scaling.enabled,Enable Cost Scaling,bool,Enables cost scaling during training.,FALSE,,,,,yes,,,FALSE,,,
training_config.cost_scaling.initial_exponent,Cost Scaling Initial Exponent,float,,20,,,,,yes,,,FALSE,,,
training_config.cost_scaling.increment,Cost Scaling Increment,float,,0.005,,,,,yes,,,FALSE,,,
training_config.cost_scaling.decrement,Cost Scaling Decrement,float,,1,,,,,yes,,,FALSE,,,
training_config.checkpoint_interval,Checkpoint Interval,integer,The interval (in epochs) at which train saves intermediate models.,1,,0,inf,,yes,,,FALSE,,,
training_config.visualizer,Visualizer configuration,collection,,,,,,,,,,FALSE,,,
training_config.visualizer.enabled,Visualizer enabled,bool,Boolean flag to enable TensorBoard visualization,FALSE,,,,,,,,FALSE,,,
training_config.visualizer.infrequent_logging_frequency,Media logging frequency,int,Interval to plot infrequent visualization collaterals (in number of epochs),5,,,,,,,,FALSE,,,
training_config.visualizer.scalar_logging_frequency,Scalar logging frequency,int,Number of points per epoch,,,,,,,,,FALSE,,,
training_config.visualizer.num_images,Visualizer batch size,int,Number of images to be visualized at every training_config.visualizer.infrequent_logging_summary,3,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config,W&B config,collection,Weights and Biases Configuration,,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config.project,W&B project name,string,Name of the weights and biases project to upstream the visualization data.,,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config.entity,W&B entity name,string,Name of the weights and biases entity the project belonds to,,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config.notes,W&B notes,string,String note about the experiment,,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config.name,W&B experiment name,string,Name of the weights and biases experiment,,,,,,,,,FALSE,,,
training_config.visualizer.wandb_config.tags,W&B tags,string,Tag of the weights and biases experiment,,,,,,,,,FALSE,,,
training_config.visualizer.clearml_config,ClearML config,collection,ClearML Configuration,,,,,,,,,FALSE,,,
training_config.visualizer.clearml_config.project,ClearML project name,string,Name of the ClearML project to upstream the visualization data.,,,,,,,,,FALSE,,,
training_config.visualizer.clearml_config.task,ClearML experiment name,string,Name of the ClearML experiment,,,,,,,,,FALSE,,,
training_config.visualizer.clearml_config.tags,ClearML tags,string,Tag of the ClearML experiment,,,,,,,,,FALSE,,,
evaluation_config,Evaluation,collection,,,,,,,yes,,,FALSE,,,
evaluation_config.average_precision_mode,Average Precision Mode,ordered,The mode in which the average precision for each class is calculated.,__SAMPLE__,,,,"__SAMPLE__,__INTEGRATE__",,,,FALSE,,,
evaluation_config.validation_period_during_training,Validation Period During Training,integer,The interval at which evaluation is run during training. The evaluation is run at this interval starting from the value of the first validation epoch parameter as specified below.,10,,0,inf,,yes,,,FALSE,,,
evaluation_config.first_validation_epoch,First Validation Epoch,integer,"The first epoch to start running validation. Ideally it is preferred to wait for at least 20-30% of the total number of epochs before starting evaluation,since the predictions in the initial epochs would be fairly inaccurate. Too many candidate boxes may be sent to clustering and this can cause the evaluation to slow down.",30,,1,inf,,yes,,,FALSE,,,
cost_function_config,Cost function ,collection,,,,,,,,,,FALSE,,,
cost_function_config.enable_autoweighting,Auto-Weighting,bool,,TRUE,,,,,yes,,,FALSE,,,
cost_function_config.max_objective_weight,Maximum Objective Weight,float,,0.999899983,,,,,,,,FALSE,,,
cost_function_config.min_objective_weight,Minimum Objective Weight,float,,1.00E-04,,,,,,,,FALSE,,,
classwise_config,Class-wise organized parameters,list,,,,,,,,,,FALSE,,,
classwise_config.key,Class Key,string,Name of class for the classwise parameters,,person,,,,,,,FALSE,,,
classwise_config.value.evaluation_config,Evaluation config elements per class,collection,,,,,,,,,,FALSE,,,
classwise_config.value.evaluation_config.minimum_detection_ground_truth_overlap,Minimum Detection Ground Truth Overlaps,float,Minimum IOU between ground truth and predicted box after clustering to call a valid detection. This parameter is a repeatable dictionary and a separate one must be defined for every class.,0.5,,0,1,,yes,,,FALSE,,,
classwise_config.value.evaluation_config.evaluation_box_config.minimum_height,Minimum Height,integer,Minimum height in pixels for a valid ground truth and prediction bbox.,20,,0,,,yes,,,FALSE,,,
classwise_config.value.evaluation_config.evaluation_box_config.maximum_height,Maximum Height,integer,Maximum height in pixels for a valid ground truth and prediction bbox.,9999,,0,,,yes,,,FALSE,,,
classwise_config.value.evaluation_config.evaluation_box_config.minimum_width,Minimum Width,integer,Minimum width in pixels for a valid ground truth and prediction bbox.,10,,0,,,yes,,,FALSE,,,
classwise_config.value.evaluation_config.evaluation_box_config.maximum_width,Maximum Width,integer,Maximum width in pixels for a valid ground truth and prediction bbox.,9999,,0,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config,Class-wise cost fuction config per class,collection,,,,,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config.class_weight,Class Weight,float,,4,,1,4,,yes,,,,,,
classwise_config.value.cost_function_config.coverage_foreground_weight,Coverage Forground Weight,float,,0.050000001,,,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config.objectives,Objectives,list,,"[{""name"": ""cov"",""initial_weight"": 1.0,""weight_target"": 1.0},{""name"": ""bbox"",""initial_weight"": 10.0,""weight_target"": 10.0}]",,,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config.objectives.name,Objective Name,string,Objective name such as cov or bbox.,cov,,,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config.objectives.initial_weight,Initial Weight,float,Initial weight for named objective.,1,,,,,yes,,,FALSE,,,
classwise_config.value.cost_function_config.objectives.weight_target,Weight Target,float,Target weight for named objective.,1,,,,,yes,,,FALSE,,,
classwise_config.value.bbox_rasterizer_config,Rasterization,collection,,,,,,,yes,,,FALSE,,,
classwise_config.value.bbox_rasterizer_config.cov_center_x,Center of Object X-Coordinate,float,x-coordinate of the center of the object,0.5,,0.3,0.7,,yes,,,,,,
classwise_config.value.bbox_rasterizer_config.cov_center_y,Center of Object Y-Coordinate,float,y-coordinate of the center of the object,0.5,,0.3,0.7,,yes,,,,,,
classwise_config.value.bbox_rasterizer_config.cov_radius_x,Center of Object X-Radius,float,x-radius of the coverage ellipse,1,,0.7,1,,yes,,,,,,
classwise_config.value.bbox_rasterizer_config.cov_radius_y,Center of Object Y-Radius,float,y-radius of the coverage ellipse,1,,0.7,1,,yes,,,,,,
classwise_config.value.bbox_rasterizer_config.bbox_min_radius,Bounding Box Minimum Radius,float,The minimum radius of the coverage region to be drawn for boxes,1,,0,1,,yes,,,,,,
classwise_config.postprocessing_config,Post-Processing,collection,,,,,,,,,,FALSE,,,
classwise_config.postprocessing_config.clustering_config.coverage_threshold,Coverage Threshold,float,The minimum threshold of the coverage tensor output to be considered a valid candidate box for clustering. The four coordinates from the bbox tensor at the corresponding indices are passed for clustering.,0.0075,,0,1,,yes,,,,,,
classwise_config.postprocessing_config.clustering_config.dbscan_eps,DBSCAN Samples Distance,float,"The maximum distance between two samples for one to be considered in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. The greater the dbscan_eps value,the more boxes are grouped together.",0.230000004,,0,1,,yes,,,,,,
classwise_config.postprocessing_config.clustering_config.dbscan_min_samples,DBSCAN Minimum Samples,int,The total weight in a neighborhood for a point to be considered as a core point. This includes the point itself.,1,,1,inf,,yes,,,,,,
classwise_config.postprocessing_config.clustering_config.minimum_bounding_box_height,Minimum Bounding Box Height,integer,The minimum height in pixels to consider as a valid detection post clustering.,20,,0,10000,,yes,,,,,,
classwise_config.postprocessing_config.clustering_config.clustering_algorithm,Clustering Algorithm,ordered,"Defines the post-processing algorithm to cluter raw detections to the final bbox render. When using HYBRID mode,ensure both DBSCAN and NMS configuration parameters are defined.",__DBSCAN__,,,,"__DBSCAN__,__NMS__,__HYBRID__",yes,,,FALSE,,,
classwise_config.postprocessing_config.clustering_config.dbscan_confidence_threshold,DBSCAN Confidence Threshold,float,The confidence threshold used to filter out the clustered bounding box output from DBSCAN.,0.1,,0.01,0.8,,yes,,,TRUE,,,
classwise_config.postprocessing_config.clustering_config.nms_iou_threshold,NMS IOU Threshold,float,The Intersection Over Union (IOU) threshold to filter out redundant boxes from raw detections to form final clustered outputs.,0.2,,0,1,,,,,,,,
classwise_config.postprocessing_config.clustering_config.nms_confidence_threshold,NMS Confidence Threshold,float,The confidence threshold to filter out clustered bounding boxes from NMS.,0,,0,1,,,,,,,,