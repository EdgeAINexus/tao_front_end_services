,parameter,display_name,value_type,description,default_value,examples,valid_min,valid_max,valid_options,required,regex,popular,param_type (internal / hidden / inferred),CLI
,gpus,number of gpus,integer,,1,,,,,,,,,
,use_amp,,bool,,FALSE,,,,,,,,,
,version,Schema Version,const,The version of this schema,1,,,,,,,,internal,
,experiment_spec_file,,hidden,,,,,,,,,,,CLI argument
,results_dir,,hidden,,,,,,,,,,,CLI argument
,key,,hidden,,,,,,,,,,,CLI argument
,random_seed,Random Seed,integer,Seed value for the random number generator in the network,42,,,,,,,,,
,dataset_config,Dataset,collection,Parameters to configure the dataset,,,,,,,,,,
,dataset_config.data_sources.label_directory_path,KITTI label path,hidden,,,,,,,,,,hidden,
,dataset_config.data_sources.image_directory_path,Image path,hidden,,,,,,,,,,,
,dataset_config.data_sources.tfrecords_directory_path,TFRecords path,hidden,,,,,,,,,,,
,dataset_config.target_class_mapping,Target Class Mappings,list,"This parameter maps the class names in the dataset to the target class to be trained in the network. An element is defined for every source class to target class mapping. This field was included with the intention of grouping similar class objects under one umbrella. For example: car, van, heavy_truck etc may be grouped under automobile.",,,,,,,,,,
,dataset_config.target_class_mapping.key,Class Key,string,"The ""key"" field is the value of the class name in the tfrecords file.",person,,,,,,"^[-a-zA-Z0-9_]{1,40}$",,,
,dataset_config.target_class_mapping.value,Class Value,string,"The ""value"" field corresponds to the value that the network is expected to learn.",person,,,,,,"^[-a-zA-Z0-9_]{1,40}$",,,
,dataset_config.validation_data_sources.label_directory_path,KITTI label path,string,,,,,,,,,,,
,dataset_config.validation_data_sources.image_directory_path,Image path,string,,,,,,,,,,,
,dataset_config.validation_data_sources.tfrecords_directory_path,TFRecords path,string,,,,,,,,,,,
,training_config,Training,collection,,,,,,,,,,,
,training_config.batch_size_per_gpu,Batch Size Per GPU,integer,The number of images per batch per GPU.,8,,1,,,,,,,
,training_config.num_epochs,Number of Epochs,integer,The total number of epochs to run the experiment.,100,,1,,,,,,,
,training_config.enable_qat,Enable Quantization Aware Training,bool,bool,FALSE,,,,,,,,,
,training_config.learning_rate.soft_start_annealing_schedule.min_learning_rate,Minimum Learning Rate,float,The minimum learning rate in the learning rate schedule.,4.00E-05,,0,,,,,,,
,training_config.learning_rate.soft_start_annealing_schedule.max_learning_rate,Maximum Learning Rate,float,The maximum learning rate in the learning rate schedule.,1.50E-02,,0,,,,,,,
,training_config.learning_rate.soft_start_annealing_schedule.soft_start,Soft Start,float,The time to ramp up the learning rate from minimum learning rate to maximum learning rate.,0.1,,0,1,,,,,,
,training_config.learning_rate.soft_start_annealing_schedule.annealing,Annealing,float,The time to cool down the learning rate from maximum learning rate to minimum learning rate. Greater than soft_start.,0.3,,0,1,,,,,,
,training_config.regularizer.type,Regularizer Type,string,The type of the regularizer being used.,__L1__,,,,"__L1__, __L2__",,,,,
,training_config.regularizer.weight,Regularizer Weight,float,The floating point weight of the regularizer.,2.00E-05,,0,,,,,,,
,training_config.checkpoint_interval,Checkpoint Interval,integer,The interval (in epochs) at which train saves intermediate models.,10,,,,,,,,,
,training_config.max_queue_size,Max Queue Size,integer,Maximum Queue Size in Sequence Dataset,,,,,,,,,,
,training_config.n_workers,Workers,integer,Number of workers in sequence dataset,2,,,,,,,,,
,training_config.use_multiprocessing,Use Multiprocessing,bool,Use multiprocessing or not,,,,,,,,,,
,training_config.early_stopping,Early Stopping,collection,,,,,,,,,,,
,training_config.early_stopping.monitor,Monitor,string,The name of the quantity to be monitored for early stopping,,,,,,,,,,
,training_config.early_stopping.min_delta,Min Delta,float,Minimum delta of the quantity to be regarded as changed,,,,,,,,,,
,training_config.early_stopping.patience,Patience,integer,The number of epochs to be waited for before stopping the training,,,,,,,,,,
,training_config.visualizer,Visualizer,collection,,,,,,,,,,,
,training_config.visualizer.enabled,Enable,bool,Enable the visualizer or not,,,,,,,,,,
,training_config.visualizer.num_images,Max Num Images,integer,Maximum number of images to be displayed in TensorBoard,,,,,,,,,,
,training_config.visualizer.wandb_config,W&B config,collection,Weights and Biases Configuration,,,,,,,,,,
,training_config.visualizer.wandb_config.project,W&B project name,string,Name of the weights and biases project to upstream the visualization data.,,,,,,,,,,
,training_config.visualizer.wandb_config.entity,W&B entity name,string,Name of the weights and biases entity the project belonds to,,,,,,,,,,
,training_config.visualizer.wandb_config.notes,W&B notes,string,String note about the experiment,,,,,,,,,,
,training_config.visualizer.wandb_config.name,W&B experiment name,string,Name of the weights and biases experiment,,,,,,,,,,
,training_config.visualizer.wandb_config.tags,W&B tags,string,Tag of the weights and biases experiment,,,,,,,,,,
,training_config.visualizer.clearml_config,ClearML config,collection,ClearML Configuration,,,,,,,,,,
,training_config.visualizer.clearml_config.project,ClearML project name,string,Name of the ClearML project to upstream the visualization data.,,,,,,,,,,
,training_config.visualizer.clearml_config.task,ClearML experiment name,string,Name of the ClearML experiment,,,,,,,,,,
,training_config.visualizer.clearml_config.tags,ClearML tags,string,Tag of the ClearML experiment,,,,,,,,,,
,training_config.optimizer.sgd,,collection,One of SGD / ADAM / RMSPROP,,,,,,,,,,
,training_config.optimizer.sgd.momentum,,float,,0.9,,,,,,,,,
,training_config.optimizer.sgd.nesterov,,bool,,FALSE,,,,,,,,,
,eval_config,Evaluation,collection,,,,,,,,,,,
,eval_config.average_precision_mode,Average Precision Mode,string,The mode in which the average precision for each class is calculated.,__SAMPLE__,,,,"__SAMPLE__, __INTEGRATE__",,,,,
,eval_config.validation_period_during_training,Validation Period During Training,integer,The interval at which evaluation is run during training. The evaluation is run at this interval starting from the value of the first validation epoch parameter as specified below.,10,,1,,,,,,,
,eval_config.batch_size,Batch Size,integer,batch size for evaluation,8,,1,,,,,,,
,eval_config.matching_iou_threshold,Matching IoU Threshold,float,IoU threshold,0.5,,0,1,,,,,,
,eval_config.visualize_pr_curve,Visualize PR Curve,bool,Whether or not to visualize precision-recall curve,,,,,,,,,,
,nms_config.confidence_threshold,Confidence Threshold,float,Confidence threshold,0.01,,0,1,,,,,,
,nms_config.clustering_iou_threshold,IoU threshold,float,IoU threshold,0.6,,0,1,,,,,,
,nms_config.top_k,Top K,integer,Maximum number of objects after NMS,200,,,,,,,,,
,nms_config.infer_nms_score_bits,NMS Score Bits,integer,Number of bits for scores for optimized NMS,,,,,,,,,,
,augmentation_config,Augmentation config,collection,,,,,,,,,,,
,augmentation_config.output_width,Model Input width,integer,,1280,,,,,,,yes,,
,augmentation_config.output_height,Model Input height,integer,,736,,,,,,,yes,,
,augmentation_config.output_channel,Model Input channel,integer,,3,,,,,,,yes,,
,augmentation_config.random_crop_min_scale,Random Crop Min Scale,float,the minimum random crop size,,,,,,,,,,
,augmentation_config.random_crop_max_scale,Random Crop Max Scale,float,the maximum random crop size,,,,,,,,,,
,augmentation_config.random_crop_min_ar,Random Crop Max Aspect Ratio,float,the minimum random crop aspect ratio,,,,,,,,,,
,augmentation_config.random_crop_max_ar,Random Crop MIin Aspect Ratio,float,the maximum random crop aspect ratio,,,,,,,,,,
,augmentation_config.zoom_out_min_scale,Zoom Out Min Scale,float,Minimum scale of ZoomOut augmentation,,,,,,,,,,
,augmentation_config.zoom_out_max_scale,Zoom Out Max Scale,float, Maximum scale of ZoomOut augmentation,,,,,,,,,,
,augmentation_config.brightness,Brightness,integer,Brightness delta in color jittering augmentation,,,,,,,,,,
,augmentation_config.contrast,Contrast,float,Contrast delta factor in color jitter augmentation,,,,,,,,,,
,augmentation_config.saturation,Saturation,float,Saturation delta factor in color jitter augmentation,,,,,,,,,,
,augmentation_config.hue,Hue,float,Hue delta in color jittering augmentation,,,,,,,,,,
,augmentation_config.random_flip,Random Flip,float,Probablity of performing random horizontal flip,,,,,,,,,,
,augmentation_config.image_mean,Image Mean,collection,"A key/value pair to specify image mean values. If omitted, ImageNet mean will be used for image preprocessing. If set, depending on output_channel, either ‘r/g/b’ or ‘l’ key/value pair must be configured.",,,,,,,,,,
,augmentation_config.image_mean.key,,string,,,,,,,,,,,
,augmentation_config.image_mean.value,,float,,,,,,,,,,,
,retinanet_config.aspect_ratios_global,Aspect Ratio Global,string,The anchor boxes of aspect ratios defined in aspect_ratios_global will be generated for each feature layer used for prediction. Note that either the aspect_ratios_global or aspect_ratios parameter is required; you don’t need to specify both.,"[1.0, 2.0, 0.5]",,,,,,,,,
Note: Either the aspect_ratios_global or aspect_ratios parameter is required; you don’t need to specify both.,retinanet_config.aspect_ratios,Aspect Ratio,string,The aspect ratio of anchor boxes for different RetinaNet feature layers,,,,,,,,,,
,retinanet_config.aspect_ratios_global,,string,,"[1.0, 2.0, 0.5]",,,,,,,,,
,retinanet_config.two_boxes_for_ar1,Two boxes for aspect-ratio=1,bool,"If this parameter is True, two boxes will be generated with an aspect ratio of 1.",FALSE,,,,,,,,,
,retinanet_config.clip_boxes,Clip Boxes,bool,"If true, all corner anchor boxes will be truncated so they are fully inside the feature images.",FALSE,,,,,,,,,
,retinanet_config.variances,Variance,string,A list of 4 positive floats to decode bboxes ,"[0.1, 0.1, 0.2, 0.2]",,,,,,,,,
,retinanet_config.scales,Scales,string,A list of positive floats containing scaling factors per convolutional predictor layer,"[0.045, 0.09, 0.2, 0.4, 0.55, 0.7]",,,,,,,,,
,retinanet_config.steps,Steps,string,An optional list inside quotation marks with a length that is the number of feature layers for prediction.The elements should be floats or tuples/lists of two floats. The steps define how many pixels apart the anchor-box center points should be,,,,,,,,,,
,retinanet_config.offsets,Offsets,string,"An optional list of floats inside quotation marks with length equal to the number of feature layers for prediction. The first anchor box will have a margin of offsets[i]*steps[i] pixels from the left and top borders. If offsets are not provided, 0.5 will be used as default value.",,,,,,,,,,
,retinanet_config.arch,Arch,string,The backbone for feature extraction,resnet,,,,,,,,,
,retinanet_config.nlayers,Number of Layers,integer,The number of conv layers in a specific arch,18,,,,,,,,,
,retinanet_config.freeze_bn,Freeze BN,bool,Whether to freeze all batch normalization layers during training.,FALSE,,,,,,,,,
,retinanet_config.freeze_blocks,Freeze Blocks,list,The list of block IDs to be frozen in the model during training,,,,,,,,,,
,retinanet_config.loss_loc_weight,Localization loss weight,float,This is a positive float controlling how much location regression loss should contribute to the final loss. The final loss is calculated as classification_loss + loss_loc_weight * loc_loss,0.8,,,,,,,,,
,retinanet_config.focal_loss_alpha,Alpha (Focal loss) ,float,Alpha in the focal loss equation,0.25,,,,,,,,,
,retinanet_config.focal_loss_gamma,Gamma (Focal loss) ,float,Gamma in the focal loss equation,2,,,,,,,,,
,retinanet_config.n_kernels,Number of kernels,integer,This setting controls the number of convolutional layers in the RetinaNet subnets for classification and anchor box regression. A larger value generates a larger network and usually means the network is harder to train.,1,,,,,,,,,
,retinanet_config.feature_size,Feature size,integer,"This setting controls the number of channels of the convolutional layers in the RetinaNet subnets for classification and anchor box regression. A larger value gives a larger network and usually means the network is harder to train. Note that RetinaNet FPN generates 5 feature maps, thus the scales field requires a list of 6 scaling factors. The last number is not used if two_boxes_for_ar1 is set to False. There are also three underlying scaling factors at each feature map level (2^0, 2^⅓, 2^⅔ ).",256,,,,,,,,,
,retinanet_config.pos_iou_thresh,Postive IOU threshold,float,The intersection-over-union similarity threshold that must be met in order to match a given ground truth box to a given anchor box.,,,,,,,,,,
,retinanet_config.neg_iou_thresh,Negative IOU threshold,float,"The maximum allowed intersection-over-union similarity of an anchor box with any ground truth box to be labeled a negative (i.e. background) box. If an anchor box is neither a positive, nor a negative box, it will be ignored during training.",,,,,,,,,,
,retinanet_config.n_anchor_levels,Number of Anchor levels,integer,Number of anchor levels between two adjacent scales.,1,,,,,,,,,