comments,parameter,display_name,value_type,description,default_value,examples,valid_min,valid_max,valid_options,required,regex,popular,valid_options_description
,engine_file,engine file path,hidden,,,,
,batch_size,batch_size,integer,"TensorRT engine batch size (default 1). If meet with out-of-memory issue, please decrease the batch size accordingly.",4,,,,,,,yes
,max_batch_size,max_batch_size,integer,"maximum TensorRT engine batch size (default 1). If meet with out-of-memory issue, please decrease the batch size accordingly.",4,,,,,,,yes
,batches,Number of calibration batches,integer,Number of batches to calibrate the model when run in INT8 mode,5,,,,,,,yes
,data_type,data_type,string,TensorRT data type,fp32,,,,"fp32,fp16,int8",,,yes
,max_workspace_size,max_workspace_size,integer,"maximum workspace size of TensorRT engine (default 1<<30). If meet with out-of-memory issue, please increase the workspace size accordingly.",,,
,model_path,onnx model from export,hidden,,,,
,gpus,number of gpus,integer,,1,,,,,,,,
,use_amp,,bool,,FALSE,,,,,,,,
,version,Schema Version,const,The version of this schema,1,,,,,,,,
Generates randomness around a point. Seed is where you begin try converging towards. Only required if needed to replicate a run. Does the log push out this value?,random_seed,Random Seed,integer,Seed value for the random number generator in the network,42,,,,,,,,>=0
,verbose,Verbose,bool,Flag of verbosity,TRUE,,,,,,,,"TRUE, FALSE"
,dataset_config,Dataset,collection,Parameters to configure the dataset,,,,,,,,,
JPG/PNG - auto pick this up,dataset_config.image_extension,Image Extension,string,Extension of the images to be used.,png,,,,"png,jpg",yes,,,"__png__, __jpg__, __jpeg__"
Can be system generated - after conversion. This is the dataset preparation step.,dataset_config.data_sources.tfrecords_path,TFRecord Path,hidden,,,/shared/users/1234/datasets/5678/tfrecords/kitti_trainval/*,,,,,,,
Where the dataset is - where the images are. Will it figure it out from the parent directory?,dataset_config.data_sources.image_directory_path,Image Path,hidden,,,/shared/users/1234/datasets/5678/training,,,,,,,
"Read all labels in the label file (car, truck, suv, person). Ask the user to map it to Vehicle/Person.",dataset_config.target_class_mapping,Target Class Mappings,list,"This parameter maps the class names in the tfrecords to the target class to be trained in the network. An element is defined for every source class to target class mapping. This field was included with the intention of grouping similar class objects under one umbrella. For example: car, van, heavy_truck etc may be grouped under automobile.",,,,,,,,,
Class you want to train for (vehicle),dataset_config.target_class_mapping.key,Class Key,string,"The ""key"" field is the value of the class name in the tfrecords file.",person,,,,,,"^[-a-zA-Z0-9_]{1,40}$",,
"Class defined in the label file (car, truck, suv -> map to vehicle)",dataset_config.target_class_mapping.value,Class Value,string,"The ""value"" field corresponds to the value that the network is expected to learn.",person,,,,,,"^[-a-zA-Z0-9_]{1,40}$",,
Default - 0,dataset_config.validation_fold,Validation Fold,integer,"In case of an n fold tfrecords, you define the index of the fold to use for validation. For sequencewise validation choose the validation fold in the range [0, N-1]. For random split partitioning, force the validation fold index to 0 as the tfrecord is just 2-fold.",0,,,,,,,,
Dataset specific config - augmentation,augmentation_config,Data Augmentation,collection,Collection of parameters to configure the preprocessing and on the fly data augmentation,,,,,,,,Yes,
The resolution at which the network should be trained for. Get the max dimesnion of images in the dataset and set the as the default behind the scenes - has to be multiple of 16.,augmentation_config.preprocessing.output_image_width,Image Width,integer,The width of the augmentation output. This is the same as the width of the network input and must be a multiple of 16.,1280,,480,,,yes,,Yes,
Get the max dimesnion of images in the dataset and set the as the default behind the scenes - has to be multiple of 16,augmentation_config.preprocessing.output_image_height,Image Height,integer,The height of the augmentation output. This is the same as the height of the network input and must be a multiple of 16.,720,,272,,,yes,,Yes,
Smaller side of image(height or width),augmentation_config.preprocessing.output_image_min,Image smaller side's size,integer,"The smaller side of image size. This is used for resize and keep aspect ratio in FasterRCNN. If this value is postive, preprocessor will resize the image and keep aspect ratio, such that the smaller side's size is this value. The other side will scale accordingly by aspect ratio. This value has to be a multiple of 16.",0,,,,,,,,
Limit of larger side's size of an image when resize and keep aspect ratio,augmentation_config.preprocessing.output_image_max,Limit of larger side's size when resize and keep aspect ratio,integer,"The maximum size of image's larger side. If after resize and keeping aspect ratio, the larger side is exceeds this limit, the image will be resized such that the larger side's size is this value, and hence the smaller side's size is smaller than output_image_min. This value has to be a multiple of 16.",0,,,,,,,,
Flag to enable automatic image scaling,augmentation_config.preprocessing.enable_auto_resize,Flag to enable or disable automatic image scaling,bool,"If True, automatic image scaling will be enabled. Otherwise, disabled.",TRUE,,,,,,,,"TRUE, FALSE"
Limit of what min dimension you DONT want to train for. Default 10x10,augmentation_config.preprocessing.min_bbox_width,Bounding Box Width,float,The minimum width of the object labels to be considered for training.,1,,0,,,yes,,,>=0
Limit of what min dimension you DONT want to train for. Default 10x10,augmentation_config.preprocessing.min_bbox_height,Bounding Box Height,float,The minimum height of the object labels to be considered for training.,1,,0,,,yes,,,>=0
3 channel default,augmentation_config.preprocessing.output_image_channel,Image Channel,integer,"The channel depth of the augmentation output. This is the same as the channel depth of the network input. Currently, 1-channel input is not recommended for datasets with JPG images. For PNG images, both 3-channel RGB and 1-channel monochrome images are supported.",3,,,,"1, 3",yes,,,"3, 1"
0,augmentation_config.preprocessing.crop_right,Crop Right,integer,The right boundary of the crop to be extracted from the original image.,0,,0,,,yes,,,>=0
0,augmentation_config.preprocessing.crop_left,Crop Left,integer,The left boundary of the crop to be extracted from the original image.,0,,0,,,yes,,,>=0
0,augmentation_config.preprocessing.crop_top,Crop Top,integer,The top boundary of the crop to be extracted from the original image.,0,,0,,,yes,,,>=0
0,augmentation_config.preprocessing.crop_bottom,Crop Bottom,integer,The bottom boundary of the crop to be extracted from the original image.,0,,0,,,yes,,,>=0
0,augmentation_config.preprocessing.scale_height,Scale Height,float,The floating point factor to scale the height of the cropped images.,0,,0,,,yes,,,>=0
0,augmentation_config.preprocessing.scale_width,Scale Width,float,The floating point factor to scale the width of the cropped images.,0,,0,,,yes,,,>=0
"Enable - go to default, disable - go to 0. Check for the right default values with TAO Toolkit Engg.",augmentation_config.spatial_augmentation.hflip_probability,Horizontal-Flip Probability,float,The probability to flip an input image horizontally.,0.5,,0,1,,,,,"[0, 1)"
"Enable - go to default, disable - go to 0. Check for the right default values with TAO Toolkit Engg.",augmentation_config.spatial_augmentation.vflip_probability,Vertical-Flip Probability,float,The probability to flip an input image vertically.,0,,0,1,,,,,"[0, 1)"
"Enable - go to default, disable - go to 1. Check for the right default values with TAO Toolkit Engg.",augmentation_config.spatial_augmentation.zoom_min,Minimum Zoom Scale,float,The minimum zoom scale of the input image.,1,,0,,,,,,"(0, 1]"
"Enable - go to default, disable - go to 1. Check for the right default values with TAO Toolkit Engg.",augmentation_config.spatial_augmentation.zoom_max,Maximum Zoom Scale,float,The maximum zoom scale of the input image.,1,,0,,,,,,"[1, 2)"
"Enable - go to default, disable - go to 0. Check for the right default values with TAO Toolkit Engg which will disable vs enable.",augmentation_config.spatial_augmentation.translate_max_x,X-Axis Maximum Traslation,float,The maximum translation to be added across the x axis.,8,,0,,,,,,>=0
"Enable - go to default, disable - go to 0. Check for the right default values with TAO Toolkit Engg.",augmentation_config.spatial_augmentation.translate_max_y,Y-Axis Maximum Translation,float,The maximum translation to be added across the y axis.,8,,0,,,,,,>=0
"Enable go tyo default, disable - 0",augmentation_config.spatial_augmentation.rotate_rad_max,Image Rotation,float,"The angle of rotation to be applied to the images and the training labels. The range is defined between [-rotate_rad_max, rotate_rad_max].",0.69,,0,,,,,,>=0
,augmentation_config.spatial_augmentation.rotate_probability,Image Rotation,float,"The probability of image rotation. The range is [0, 1]",,,,,,,,,"[0, 1)"
,augmentation_config.color_augmentation.color_shift_stddev,Color Shift Standard Deviation,float,The standard devidation value for the color shift.,0,,0,1,,,,,"[0, 1)"
,augmentation_config.color_augmentation.hue_rotation_max,Hue Maximum Rotation,float,The maximum rotation angle for the hue rotation matrix.,25,,0,360,,,,,"[0, 360)"
,augmentation_config.color_augmentation.saturation_shift_max,Saturation Maximum Shift,float,The maximum shift that changes the saturation. A value of 1.0 means no change in saturation shift.,0.2,,0,1,,,,,"[0, 1)"
,augmentation_config.color_augmentation.contrast_scale_max,Contrast Maximum Scale,float,The slope of the contrast as rotated around the provided center. A value of 0.0 leaves the contrast unchanged.,0.1,,0,1,,,,,"[0, 1)"
,augmentation_config.color_augmentation.contrast_center,Contrast Center,float,"The center around which the contrast is rotated. Ideally, this is set to half of the maximum pixel value. Since our input images are scaled between 0 and 1.0, you can set this value to 0.5.",0.5,,,,0.5,,,,0.5
Might need different defaults based on task/scenario,model_config,Model,collection,,,,,,,,,,
,model_config.arch,BackBone Architecture,string,The architecture of the backbone feature extractor to be used for training.,resnet:18,,,,resnet:18,yes,,,"resnet:10',
                            'resnet:18',
                            'resnet:34',
                            'resnet:50',
                            'resnet:101',
                            'vgg16',
                            'vgg:16',
                            'vgg:19',
                            'googlenet',
                            'mobilenet_v1',
                            'mobilenet_v2',,,,,image_type
                            'darknet:19',
                            'darknet:53',
                            'resnet101',
                            'efficientnet:b0',
                            'efficientnet:b1',"
Confirm correct default values,model_config.freeze_blocks,Freeze Blocks,integer,"This parameter defines which blocks may be frozen from the instantiated feature extractor template, and is different for different feature extractor templates.",,,0,3,,,,,depends on arch
Default values. Verify with TAO Toolkit. 2 sets of defaults required.,model_config.freeze_bn,Freeze Batch Normalization,bool,A flag to determine whether to freeze the Batch Normalization layers in the model during training.,FALSE,,,,,,,,"TRUE, FALSE"
Default values. Verify with TAO Toolkit. 2 sets of defaults required.,model_config.all_projections,All Projections,bool,"For templates with shortcut connections, this parameter defines whether or not all shortcuts should be instantiated with 1x1 projection layers, irrespective of whether there is a change in stride across the input and output.",TRUE,,,,,,,,"TRUE, FALSE"
Default values. Verify with TAO Toolkit. 2 sets of defaults required.,model_config.use_pooling,Use Pooling,bool,"Choose between using strided convolutions or MaxPooling while downsampling. When True, MaxPooling is used to downsample; however, for the object-detection network, NVIDIA recommends setting this to False and using strided convolutions.",FALSE,,,,,,,,"TRUE, FALSE"
Default values. Verify with TAO Toolkit. 2 sets of defaults required.,model_config.dropout_rate,Dropout Rate,float,Probability for drop out,0,,0,0.1,,,,,"[0, 1)"
,model_config.input_image_config,Input Image,collection,Configuration for input images,,,,,,,,,
,model_config.input_image_config.size_height_width,,collection,,,,,,,,,,
,model_config.input_image_config.size_height_width.height,,integer,,720,,,,,,,,
,model_config.input_image_config.size_height_width.width,,integer,,1280,,,,,,,,
,model_config.input_image_config.image_type,Image Type,enum,"The type of images, either RGB or GRAYSCALE",__RGB__,,,,,,,,"__RGB__, __GRAYSCALE__"
,model_config.input_image_config.size_min,Image smaller side's size,integer,"The size of an image's smaller side, should be a multiple of 16. This should be consistent with the size in augmentation_config. This is used when resizing images and keeping aspect ratio",,,,,,,,,>=0
,model_config.input_image_config.size_height_width,Image size by height and width,collection,The size of images by specifying height and width.,,,,,,,,,
,model_config.input_image_config.size_height_width.height,Image Height,integer,The height of images,,,,,,,,,>=0
,model_config.input_image_config.size_height_width.width,Image Width,integer,The width of images,,,,,,,,,>=0
,model_config.input_image_config.image_channel_order,Image Channel Order,string,"The channel order of images. Should be either ""rgb"" or ""bgr"" for RGB images and ""l"" for GRAYSCALE images",bgr,,,,,,,,"rgb', 'bgr', 'l'"
,model_config.input_image_config.image_channel_mean,Image Channel Means,list,"A dict from 'r', 'g', 'b' or 'l'(for GRAYSCALE images) to per-channel mean values.","[{""key"":""r"",""value"":103.0}, {""key"":""g"",""value"":103.0}, {""key"":""b"",""value"":103.0}]",,,,,,,,
,model_config.input_image_config.image_channel_mean.key,channel means key,string,"string => one of r,g,b",,,,,,,,,"r', 'g', 'b', 'l'"
,model_config.input_image_config.image_channel_mean.value,channel means value,float,value in float,,,,,,,,,"(0, 255)"
,model_config.input_image_config.image_scaling_factor,Image Scaling Factor,float,A scalar to normalize the images after mean subtraction.,1,,,,,,,,>0
,model_config.input_image_config.max_objects_num_per_image,Max Objects Num,integer,The maximum number of objects in an image. This is used for padding in data loader as different images can have different number of objects in its labels.,100,,,,,,,,>=1
,model_config.anchor_box_config,Anchor Boxes,Collection,,,,,,,,,,
,model_config.anchor_box_config.scale,Anchor Scales,list,The list of anchor sizes(scales).,"[64.0,128.0,256.0]",,,,,,,,>0
,model_config.anchor_box_config.ratio,Anchor Ratios,list,The list of anchor aspect ratios.,"[1.0,0.5,2.0]",,,,,,,,>0
,model_config.roi_mini_batch,ROI Batch Size,integer,The batch size of ROIs for training the RCNN in the model,16,,,,,,,,>0
,model_config.rpn_stride,RPN stride,integer,"The stride of RPN feature map, compared to input resolutions. Currently only 16 is supported.",16,,,,,,,,16
,model_config.drop_connect_rate,Drop Connect Rate,float,The rate of DropConnect. This is only useful for EfficientNet backbones.,,,,,,,,,"(0, 1)"
,model_config.rpn_cls_activation_type,RPN Classification Activation Type,string,"Type of RPN classification head's activation function. Currently only ""sigmoid"" is supported.",,,,,,,,,sigmoid
,model_config.use_bias,Use Bias,bool,Whether or not to use bias for convolutional layers,,,,,,,,,"TRUE, FALSE"
,model_config.roi_pooling_config,ROI Pooling,collection,Confiuration fo ROI Pooling layer,,,,,,,,,
,model_config.roi_pooling_config.pool_size,Pool Size,integer,Pool size of the ROI Pooling operation.,7,,,,,,,,>0
,model_config.roi_pooling_config.pool_size_2x,Pool Size Doubled,bool,Whether or not to double the pool size and apply a 2x downsampling after ROI Pooling,FALSE,,,,,,,,"TRUE, FALSE"
,model_config.activation,Activation,collection,Activation function for the model backbone. This is only useful for EfficientNet backbones.,,,,,,,,,
,model_config.activation.activation_type,Activation Type,string,Type of the activation function of backbone.,,,,,,,,,"relu, swish"
,model_config.activation.activation_parameters,Activation Parameters,dict,A dict the maps name of a parameter to its value.,,,,,,,,,
,training_config,Training,collection,,,,,,,,,,>0
IMPORTANT. Open to user - default should smarty calculate. Check factors that influence.,training_config.batch_size_per_gpu,Batch Size Per GPU,integer,The number of images per batch per GPU.,8,,1,,,yes,,,>0
Default - what is the optimal number of epcohs for each model. Smart feature in TAO Toolkit to auto stop once model converges,training_config.num_epochs,Number of Epochs,integer,The total number of epochs to run the experiment.,120,,1,,,yes,,Yes,"TRUE, FALSE"
Toggle for end user,training_config.enable_qat,Enable Quantization Aware Training,bool,bool,FALSE,,,,,yes,,Yes,>0
Default,training_config.learning_rate.soft_start .base_lr,Minimum Learning Rate,float,,5.00E-06,,,,,,,Yes,>0
Default,training_config.learning_rate.soft_start .start_lr,Maximum Learning Rate,float,,5.00E-04,,,,,,,Yes,"(0, 1)"
Default,training_config.learning_rate.soft_start .soft_start,Soft Start,float,,0.100000001,,0,1,,,,Yes,>1
Default,training_config.learning_rate.soft_start .annealing_divider,Annealing,float,,0.699999988,,0,1,,,,Yes,"__NO_REG__, __L1__, __L2__"
Default,training_config.regularizer.type,Regularizer Type,string,The type of the regularizer being used.,__L1__,,,,"__NO_REG__, __L1__, __L2__",yes,,,>0
Default,training_config.regularizer.weight,Regularizer Weight,float,The floating point weight of the regularizer.,3.00E-09,,,,,yes,,,"(0, 1)"
Default,training_config.optimizer.adam.epsilon,Optimizer Adam Epsilon,float,A very small number to prevent any division by zero in the implementation.,1.00E-08,,,,,yes,,,"(0, 1)"
Default,training_config.optimizer.adam.beta_1,Optimizer Adam Beta1,float,,0.899999976,,,,,yes,,,"(0, 1)"
Default,training_config.optimizer.adam.beta_2,Optimizer Adam Beta2,float,,0.999000013,,,,,yes,,,>=1
Use default as 10. Provide last checpoint to user,training_config.checkpoint_interval,Checkpoint Interval,integer,The interval (in epochs) at which train saves intermediate models.,1,,0,,,yes,,,"TRUE, FALSE"
,training_config.enable_augmentation,Enable Augmentation,bool,Whether or not to enable data augmentation,TRUE,,,,,,,,
,training_config.retrain_pruned_model,Pruned Model,hidden,The path of pruned model to be retrained,,,,,,,,,
,training_config.pretrained_weights,Pretrained Weights,hidden,The path of the pretrained model(weights) used to initialize the model being trained,,,,,,,,,
,training_config.resume_from_model,Resume Model,hidden,The path of the model used to resume a interrupted training,,,,,,,,,"(0, 1)"
,training_config.rpn_min_overlap,RPN Min Overlap,float,The lower IoU threshold used to match anchor boxes to groundtruth boxes.,0.1,,,,,,,,"(0, 1)"
,training_config.rpn_max_overlap,RPN Max Overlap,float,The higher IoU threshold used to match anchor boxes to groundtruth boxes.,1,,,,,,,,"[0, 1)"
,training_config.classifier_min_overlap,Classifier Min Overlap,float,The lower IoU threshold used to generate the proposal target.,0.1,,,,,,,,"(0, 1)"
,training_config.classifier_max_overlap,Classifier Max Overlap,float,The higher IoU threshold used to generate the proposal target.,1,,,,,,,,"TRUE, FALSE"
,training_config.gt_as_roi,Gt As ROI,bool,A flag to include groundtruth boxes in the positive ROIs for training the RCNN,,,,,,,,,>0
,training_config.std_scaling,RPN Regression Loss Scaling,float,A scaling factor (multiplier) for RPN regression loss,1,,,,,,,,
,training_config.classifier_regr_std,RCNN Regression Loss Scaling,list,"Scaling factors (denominators) for the RCNN regression loss. A map from ¡®x¡¯, ¡®y¡¯, ¡®w¡¯, ¡®h¡¯ to its corresponding scaling factor, respectively","[{""key"":""x"",""value"":10.0},{""key"":""y"",""value"":10.0},{""key"":""w"",""value"":5.0},{""key"":""h"",""value"":5.0}]",,,,,,,,
,training_config.classifier_regr_std.key,RCNN Regression Loss Scaling Key,string,"one of x,y,h,w",,,,,,,,,>0
,training_config.classifier_regr_std.value,RCNN Regression Loss Scaling Value,float,float value for key,,,,,,,,,
,training_config.output_model,Output Model Path,hidden,Path of the output model,,,,,,,,,>0
,training_config.rpn_pre_nms_top_N,RPN Pre-NMS Top N,integer,The number of boxes (ROIs) to be retained before the NMS in Proposal layer,12000,,,,,,,,>=1
,training_config.rpn_mini_batch,RPN Mini Batch,integer,The batch size to train RPN,16,,,,,,,,>0
,training_config.rpn_nms_max_boxes,RPN NMS Max Boxes,integer,The maximum number of boxes (ROIs) to be retained after the NMS in Proposal layer,2000,,,,,,,,"(0, 1)"
,training_config.rpn_nms_overlap_threshold,RPN NMS IoU Threshold,float,The IoU threshold for NMS in Proposal layer,0.7,,,,,,,,>0
,training_config.lambda_rpn_regr,RPN Regression Loss Weighting,float,Weighting factor for RPN regression loss,1,,,,,,,,>0
,training_config.lambda_rpn_class,RPN classification Loss Weighting,float,Weighting factor for RPN classification loss.,1,,,,,,,,>0
,training_config.lambda_cls_regr,RCNN Regression Loss Weighting,float,Weighting factor for RCNN regression loss,1,,,,,,,,>0
,training_config.lambda_cls_class,RCNN Classification Loss Weighting,float,Weighting factor for RCNN classification loss,1,,,,,,,,list of floats
,training_config.model_parallelism,Model Parallelism,list of floats,List of fractions for model parallelism,,,,,,,,,
,training_config.early_stopping,Early Stopping,collection,,,,,,,,,,"""loss"""
,training_config.early_stopping.monitor,Monitor,string,The name of the quantity to be monitored for early stopping,,,,,,,,,>=0
,training_config.early_stopping.min_delta,Min Delta,float,Minimum delta of the quantity to be regarded as changed,,,,,,,,,>0
,training_config.early_stopping.patience,Patience,integer,The number of epochs to be waited for before stopping the training,,,,,,,,,
,training_config.visualizer,Visualizer,collection,,,,,,,,,,"TRUE, False"
,training_config.visualizer.enabled,Enable,bool,Enable the visualizer or not,,,,,,,,,>=1
,training_config.visualizer.num_images,Max Num Images,integer,Maximum number of images to be displayed in TensorBoard,,,,,,,,,
,training_config.visualizer.wandb_config,W&B config,collection,Weights and Biases Configuration,,,,,,,,,
,training_config.visualizer.wandb_config.project,W&B project name,string,Name of the weights and biases project to upstream the visualization data.,,,,,,,,,
,training_config.visualizer.wandb_config.entity,W&B entity name,string,Name of the weights and biases entity the project belonds to,,,,,,,,,
,training_config.visualizer.wandb_config.notes,W&B notes,string,String note about the experiment,,,,,,,,,
,training_config.visualizer.wandb_config.name,W&B experiment name,string,Name of the weights and biases experiment,,,,,,,,,
,training_config.visualizer.wandb_config.tags,W&B tags,string,Tag of the weights and biases experiment,,,,,,,,,
,training_config.visualizer.clearml_config,ClearML config,collection,ClearML Configuration,,,,,,,,,
,training_config.visualizer.clearml_config.project,ClearML project name,string,Name of the ClearML project to upstream the visualization data.,,,,,,,,,
,training_config.visualizer.clearml_config.task,ClearML experiment name,string,Name of the ClearML experiment,,,,,,,,,
,training_config.visualizer.clearml_config.tags,ClearML tags,string,Tag of the ClearML experiment,,,,,,,,,
,evaluation_config,Evaluation,collection,,,,,,,yes,,,
,evaluation_config.model,Model Path,string,The path to the model to run inference,,,,,,,,,>=1
,evaluation_config.rpn_pre_nms_top_N,RPN Pre-NMS Top N,integer,The number of boxes (ROIs) to be retained before the NMS in Proposal layer during evaluation,6000,,,,,,,,"(0, 1)"
,evaluation_config.rpn_nms_overlap_threshold,RPN overlap threshold,float,,0.7,,,,,,,,>0
,evaluation_config.rpn_nms_max_boxes,RPN NMS Max Boxes,integer,The maximum number of boxes (ROIs) to be retained after the NMS in Proposal layer,300,,,,,,,,>0
,evaluation_config.classifier_nms_max_boxes,Classifier NMS Max Boxes,integer,The maxinum numbere of boxes for RCNN NMS,100,,,,,,,,"(0, 1)"
,evaluation_config.classifier_nms_overlap_threshold,Classifier NMS Overlap Threshold,float,The NMS overlap threshold in RCNN,0.3,,,,,,,,"(0, 1)"
,evaluation_config.object_confidence_thres,Object Confidence Threshold,float,The objects confidence threshold,0.00001,,,,,,,,"TRUE, FALSE"
,evaluation_config.use_voc07_11point_metric,Use VOC 11-point Metric,bool,Whether to use PASCAL-VOC 11-point metric,,,,,,,,,>=1
,evaluation_config.validation_period_during_training,Validation Period,integer,The period(number of epochs) to run validation during training,,,,,,,,,>=1
,evaluation_config.batch_size,Batch Size,integer,The batch size for evaluation,,,,,,,,,"(0, 1)"
,evaluation_config.trt_evaluation,TensorRT Evaluation,Collection,TensorRT evaluation,,,,,,,,,
,evaluation_config.trt_evaluation.trt_engine,Trt Engine,String,TRT Engine,,,,,,,,,"(0, 1)"
,evaluation_config.gt_matching_iou_threshold,Gt Matching IoU Threshold,float,The IoU threshold to match groundtruth to detected objects. Only one of this collection or gt_matching_iou_threshold_range,0.5,,,,,,,,"(0, 1)"
,evaluation_config.gt_matching_iou_threshold_range,Gt Matching IoU Threshold Range,collection,Only one of this collection or gt_matching_iou_threshold,,,,,,,,,"(0, 1)"
,evaluation_config.gt_matching_iou_threshold_range.start,Start,float,The starting value of the IoU range,,,,,,,,,"TRUE, FALSE"
,evaluation_config.gt_matching_iou_threshold_range.end,End,float,The end point of the IoU range(exclusive),,,,,,,,,
,evaluation_config.gt_matching_iou_threshold_range.step,Step,float,The step size of the IoU range,,,,,,,,,
,evaluation_config.visualize_pr_curve,Visualize PR Curve,bool,Visualize precision-recall curve or not,,,,,,,,,
,inference_config,,,,,,,,,,,,>=1
,inference_config.images_dir,Images Directory,hidden,Path to the directory of images to run inference on,,,,,,,,,>0
,inference_config.model,Model Path,hidden,Path to the model to run inference on,,,,,,,,,>0
,inference_config.batch_size,Batch Size,integer,The batch size for inference,1,,,,,,,,"(0, 1)"
,inference_config.rpn_pre_nms_top_N,RPN Pre-NMS Top N,integer,The number of boxes (ROIs) to be retained before the NMS in Proposal layer during inference,6000,,,,,,,,"(0, 1)"
,inference_config.rpn_nms_max_boxes,RPN NMS Max Boxes,integer,The maximum number of boxes (ROIs) to be retained after the NMS in Proposal layer,300,,,,,,,,"(0, 1)"
,inference_config.rpn_nms_overlap_threshold,RPN NMS IoU Threshold,float,The IoU threshold for NMS in Proposal layer,0.7,,,,,,,,>0
,inference_config.bbox_visualize_threshold,Visualization Threshold,float,The confidence threshold for visualizing the bounding boxes,0.6,,,,,,,,"(0, 1)"
,inference_config.object_confidence_thres,Object Confidence Threshold,float,The objects confidence threshold,0.00001,,,,,,,,
,inference_config.classifier_nms_max_boxes,Classifier NMS Max Boxes,integer,The maxinum numbere of boxes for RCNN NMS,100,,,,,,,,"True, False"
,inference_config.classifier_nms_overlap_threshold,Classifier NMS Overlap Threshold,float,The NMS overlap threshold in RCNN,0.3,,,,,,,,
,inference_config.detection_image_output_dir,Image Output Directory,string,Path to the directory to save the output images during inference,,,,,,,,,"0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10"
,inference_config.bbox_caption_on,Bbox Caption,bool,Enable text caption for bounding box or not,,,,,,,,,
,inference_config.labels_dump_dir,Labels Ouptut Directory,hidden,Path to the directory to save the output labels,,,,,,,,,
,inference_config.nms_score_bits,NMS Score Bits,integer,Number of score bits in optimized NMS,,,,,,,,,
,inference_config.trt_inference,TensorRT Inference,Collection,TensorRT inference configurations,,,,,,,,,
,inference_config.trt_inference.trt_engine,TensorRT Engine,hidden,Path to the TensorRT engine to run inference,,,,,,,,,