# Copyright (c) 2023, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Dataset upload modules"""
import tarfile
import os
import glob
import sys

from handlers.cloud_storage import create_cs_instance


# Simple helper class for ease of code migration
class SimpleHandler:
    """Helper class holding dataset information"""

    def __init__(self, org_name, handler_metadata, temp_dir="", workspace_metadata=None):
        """Initialize the Handler helper class"""
        self.root = temp_dir
        self.type = handler_metadata.get("type")
        self.format = handler_metadata.get("format")
        self.intent = handler_metadata.get("use_for", [])
        assert type(self.intent) is list
        self.cloud_instance = None
        if workspace_metadata:
            self.cloud_instance, _ = create_cs_instance(workspace_metadata)

    def check_for_file_existence(self, path, file_type="file"):
        if self.cloud_instance:
            if file_type == "file":
                return self.cloud_instance.is_file(path)
            path = path[1:] if path.startswith("/") else path
            return self.cloud_instance.is_folder(path)
        return os.path.exists(path)


def _untar_file(tar_path, dest, strip_components=0):
    """Function to untar a file"""
    os.makedirs(dest, exist_ok=True)
    with tarfile.open(tar_path, 'r') as tar:
        for member in tar.getmembers():
            # Remove leading directory components using strip_components
            components = member.name.split(os.sep)
            if len(components) > strip_components:
                member.name = os.path.join(*components[strip_components:])
            if member.isdir():
                # Make subdirs ahead because tarfile extracts them with user permissions only
                os.makedirs(os.path.join(dest, member.name), exist_ok=True)
            tar.extract(member, path=dest, set_attrs=False)


def _extract_images(tar_path, dest):
    """Function to extract images, other directories on same level as images to root of dataset"""
    # Infer how many components to strip to get images,labels to top of dataset directory
    # Assumes: images, other necessary directories are in the same level
    with tarfile.open(tar_path) as tar:
        strip_components = 0
        names = [tinfo.name for tinfo in tar.getmembers()]
        for name in names:
            if "/images/" in name:
                strip_components = name.split("/").index("images")
                break
    # Build shell command for untarring
    print("Untarring data started", file=sys.stderr)
    _untar_file(tar_path, dest, strip_components)
    print("Untarring data complete", file=sys.stderr)

    # Remove .tar.gz file
    print("Removing data tar file", file=sys.stderr)
    os.remove(tar_path)
    print("Deleted data tar file", file=sys.stderr)


def write_dir_contents(directory, file):
    """Write contents of a directory to a file"""
    with open(file, "w", encoding='utf-8') as f:
        for dir_files in sorted(glob.glob(directory + "/*")):
            f.write(dir_files + "\n")


def object_detection(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    OD Dataset structure
    Upload - uploads and untars
    - /images
    - /labels
    Convert
    - /tfrecords (generated by dataset convert)
    - /tfrecords/classes.json - A json file with a list
    Augment
    - Creates temp output folders and moves them to /images and /labels

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "images.tar.gz"))
        if handler.format == "kitti":
            assert handler.check_for_file_existence(os.path.join(handler.root, "labels.tar.gz"))
        elif handler.format == "coco":
            assert handler.check_for_file_existence(os.path.join(handler.root, "annotations.json"))
        elif handler.format == "coco_raw":
            assert handler.check_for_file_existence(os.path.join(handler.root, "label_map.txt"))
        if handler.format in ("raw", "coco_raw"):
            if handler.intent:
                assert handler.intent == ["testing"]
        return True

    except:
        return False


instance_segmentation = object_detection


def semantic_segmentation(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Upload - uploads and creates .txt files
    - /images/
    - /masks/

    No Actions
    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and masks paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "images/train.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "images/test.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "images/val.tar.gz"))
        if handler.format == "unet":
            assert handler.check_for_file_existence(os.path.join(handler.root, "masks/train.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "masks/val.tar.gz"))
        elif handler.format == "coco":
            assert handler.check_for_file_existence(os.path.join(handler.root, "annotations.json"))
        if handler.format == "raw":
            if handler.intent:
                assert handler.intent == ["testing"]
        return True

    except:
        return False


def character_recognition(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    LPRNET Dataset structure
    Upload - uploads and untars
    - /images
    - /labels
    - /characters.txt

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "image.tar.gz"))
        if handler.format != "raw":
            assert handler.check_for_file_existence(os.path.join(handler.root, "label.tar.gz"))
            assert handler.check_for_file_existence(os.path.join(handler.root, "characters.txt"))
        else:
            if handler.intent:
                assert handler.intent == ["testing"]
        return True

    except:
        return False


def ocrnet(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    OCRNET Dataset structure
    Upload - uploads and untars
    - /train/gt_new.txt: train dataset
    - /test/gt_new.txt: val dataset

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist

        assert handler.check_for_file_existence(os.path.join(handler.root, "character_list"))
        format = ""
        if handler.intent == ["training"]:
            format = "train"
        elif handler.intent == ["evaluation"]:
            format = "test"
        assert handler.check_for_file_existence(os.path.join(handler.root, format + ".tar.gz"))
        return True

    except:
        return False


def ocrnet_permission_change(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Change permission of necessary files and folders for OCRNET
    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        if handler.check_for_file_existence(os.path.join(handler.root, "train")):
            os.system(f"chmod -R 777 {os.path.join(handler.root, 'train')}")
        if handler.check_for_file_existence(os.path.join(handler.root, "test")):
            os.system(f"chmod -R 777 {os.path.join(handler.root, 'test')}")
        return True

    except:
        return False


def ocdnet(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    OCDNET Dataset structure
    Upload - uploads and untars
    - /train/img: train images
    - /train/gt: train ground_truth
    - /test/img: val images
    - /test/gt: val ground_truth

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist

        assert handler.check_for_file_existence(os.path.join(handler.root, "train.tar.gz")) or (handler.check_for_file_existence(os.path.join(handler.root, "test.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "test/img.tar.gz")))
        return True

    except:
        return False


def centerpose(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    CenterPose Dataset structure
    Upload - uploads and preprocessed
    - /train: train images and ground_truth
    - /val: val images and ground_truth
    - /test: test images and ground_truth

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist

        assert handler.check_for_file_existence(os.path.join(handler.root, "train.tar.gz")) or handler.check_for_file_existence(os.path.join(handler.root, "val.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "test.tar.gz"))
        return True

    except:
        return False


def optical_inspection(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Optical Inspection Dataset structure
    Upload - uploads and untars
    - images: images
    - dataset.csv: ground_truth

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist

        assert handler.check_for_file_existence(os.path.join(handler.root, "images.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "dataset.csv"))
        return True

    except:
        return False


def visual_changenet(org_name, handler_metadata, temp_dir="", workspace_metadata=None):  # pylint: disable=R1710
    """
    Visual Changenet Dataset structure
    Upload - uploads and untars
    - A: test_image
    - B: golden_image
    - label: change_masks
    - list: dataset_split_files
    For Classification use the optical inspection dataset structure

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate each directory exists
        if handler.format == "visual_changenet_classify":
            return optical_inspection(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
        if handler.format == "visual_changenet_segment":
            assert handler.check_for_file_existence(os.path.join(handler.root, "A.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "B.tar.gz"))
            assert handler.check_for_file_existence(os.path.join(handler.root, "list.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "label.tar.gz"))
            return True

    except:
        return False


def ml_recog(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Metric Learning Recognition Dataset structure
    Upload - uploads and untars
    - metric_learning_recognition/
      - retail-product-checkout-dataset/
      - retail-product-checkout-dataset_classification_demo/
        - known_classes
        - unknown_classes

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist

        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/known_classes/train.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/known_classes/reference.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/known_classes/val.tar.gz"))

        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/unknown_classes/train.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/unknown_classes/reference.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "metric_learning_recognition/retail-product-checkout-dataset_classification_demo/unknown_classes/test.tar.gz"))
        return True

    except:
        return False


def image_classification(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Raw:
    images/

    Default:
    images/<class1>
    images/<class2>
    ...

    Custom:
    images/
    train.csv
    val.csv

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate images and labels paths exist
        assert (handler.check_for_file_existence(os.path.join(handler.root, "images_train.tar.gz")) or handler.check_for_file_existence(os.path.join(handler.root, "images_val.tar.gz")) or handler.check_for_file_existence(os.path.join(handler.root, "images_test.tar.gz")))
        if handler.format == "custom":
            assert handler.check_for_file_existence(os.path.join(handler.root, "val.csv"))
        if handler.format == "classification_pyt":
            assert handler.check_for_file_existence(os.path.join(handler.root, "classes.txt"))
        if handler.format == "classification_tf2":
            assert handler.check_for_file_existence(os.path.join(handler.root, "classmap.json"))
        if handler.format == "raw":
            if handler.intent:
                assert handler.intent == ["testing"]
        return True
    except:
        return False


def action_recognition(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Default:
    train
    test
    ...

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "train.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "test.tar.gz"))
        return True
    except:
        return False


def pointpillars(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    OD Dataset structure
    Upload - uploads and untars
    - /images
    - /labels
    - /velodyne
    - /calib

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)

    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "train.tar.gz"))
        assert handler.check_for_file_existence(os.path.join(handler.root, "val.tar.gz"))
        return True

    except:
        return False


def pose_classification(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Default:
    kinetics/nvidia : root_folder_path
    files:
    train_data.npy
    train_label.npy
    val_data.pkl
    val_label.pkl
    ...

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "kinetics"), file_type="folder") or handler.check_for_file_existence(os.path.join(handler.root, "nvidia"), file_type="folder")

        model_type = ""
        if handler.check_for_file_existence(os.path.join(handler.root, "kinetics"), file_type="folder"):
            model_type = "kinetics"
        elif handler.check_for_file_existence(os.path.join(handler.root, "nvidia"), file_type="folder"):
            model_type = "nvidia"

        assert handler.check_for_file_existence(os.path.join(handler.root, model_type, "train_data.npy")) and handler.check_for_file_existence(os.path.join(handler.root, model_type, "train_label.pkl")) and handler.check_for_file_existence(os.path.join(handler.root, model_type, "val_data.npy")) and handler.check_for_file_existence(os.path.join(handler.root, model_type, "val_label.pkl"))
        return True

    except:
        return False


def re_identification(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Default:
    sample_train
    sample_test
    sample_test
    ...

    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate images and labels paths exist
        assert handler.check_for_file_existence(os.path.join(handler.root, "sample_train.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "sample_test.tar.gz")) and handler.check_for_file_existence(os.path.join(handler.root, "sample_query.tar.gz"))
        return True

    except:
        return False


def data_services_image(org_name, handler_metadata, temp_dir="", workspace_metadata=None):
    """
    Folder with any subfolder structure of images
    """
    handler = SimpleHandler(org_name, handler_metadata, temp_dir=temp_dir, workspace_metadata=workspace_metadata)
    try:
        # Validate images exist
        assert handler.check_for_file_existence(handler.root)
        valid_extensions = ['.jpg', '.jpeg', '.png']
        pattern = os.path.join(handler.root, '**', f'*.[{"|".join(valid_extensions)}]')
        image_files = glob.glob(pattern, recursive=True)
        assert image_files
        return True

    except:
        return False


DS_UPLOAD_TO_FUNCTIONS = {"object_detection": object_detection,
                          "semantic_segmentation": semantic_segmentation,
                          "character_recognition": character_recognition,
                          "image_classification": image_classification,
                          "instance_segmentation": instance_segmentation,
                          "action_recognition": action_recognition,
                          "ml_recog": ml_recog,
                          "ocdnet": ocdnet,
                          "ocrnet": ocrnet,
                          "optical_inspection": optical_inspection,
                          "pointpillars": pointpillars,
                          "pose_classification": pose_classification,
                          "re_identification": re_identification,
                          "visual_changenet": visual_changenet,
                          "centerpose": centerpose,
                          "image": data_services_image}

DS_CHANGE_PERMISSIONS = {"ocrnet": ocrnet_permission_change}
