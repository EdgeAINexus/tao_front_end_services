{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Notebook to demonstrate TAO-Remote Client AutoML workflow for Object Detection using Yolo-v4\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "\n",
    "\n",
    "### Learning Objective\n",
    "\n",
    "This AutoML notebook applies to identifying the optimal hyperparameters (e.g., learning rate, batch size, weight regularizer, number of layers, etc.) for Yolo-v4 (default model is Yolo-v4, a list of other supported models can be found in the subsequent cells) in order to obtain better accuracy results or converge faster on AI models for object detection application.\n",
    "- Take a pretrained model and choose automl algorithm/parameters to start AutoML train.\n",
    "- At the end of an AutoML run, you will receive a config file that specifies the best performing model, along with the binary model file to deploy it to your application.\n",
    "\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Set AutoML algorithm configurations\n",
    "  - Add/Remove AutoML parameters\n",
    "- Override train config defaults\n",
    "- Run AutoML\n",
    "\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Create a model experiment ](#head-8)\n",
    "1. [Find pretrained model](#head-9)\n",
    "1. [Set AutoML related configurations](#head-10)\n",
    "1. [Provide train specs](#head-11)\n",
    "1. [Run AutoML train](#head-12)\n",
    "1. [Get the best model from AutoML](#head-13)\n",
    "1. [Delete experiment](#head-14)\n",
    "1. [Delete datasets](#head-15)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import getpass\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "namespace = subprocess.getoutput(\"echo $(helm list -A | grep tao-toolkit-api) | cut -d' ' -f2\")\n",
    "namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore variables set in yolo_training.ipynb\n",
    "\n",
    "with open(\"variables_to_store.json\" , \"r\") as specs_file:\n",
    "    variables_to_store = json.load(specs_file)\n",
    "\n",
    "namespace = variables_to_store[\"namespace\"]\n",
    "node_addr = variables_to_store[\"node_addr\"]\n",
    "node_port = variables_to_store[\"node_port\"]\n",
    "home = variables_to_store[\"home\"]\n",
    "os.environ['USER'] = variables_to_store[\"USER\"]\n",
    "os.environ['TOKEN'] = variables_to_store[\"TOKEN\"]\n",
    "train_dataset_id = variables_to_store[\"train_dataset_id\"]\n",
    "eval_dataset_id = variables_to_store[\"eval_dataset_id\"]\n",
    "\n",
    "%env BASE_URL=http://{node_addr}:{node_port}/{namespace}/api/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Available models :\n",
    "# 1. detectnet-v2 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/detectnet_v2.html\n",
    "# 2. faster-rcnn - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/fasterrcnn.html\n",
    "# 3. yolo-v3 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v3.html\n",
    "# 4. yolo-v4 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4.html\n",
    "# 5. yolo-v4-tiny - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4_tiny.html\n",
    "\n",
    "# There are 3 other models supported for AutoML but not supported in this notebook - EfficientDet, SSD, RetinaNet\n",
    "# To run AutoML on one of these 3 models, use the notebook at wget --content-disposition 'https://api.ngc.nvidia.com/v2/resources/nvidia/tao/tao-getting-started/versions/4.0.0/files/notebooks/tao_api_starter_kit/api/automl/object_detection.ipynb'\n",
    "\n",
    "model_name = \"yolo-v4\" # You can switch the model_name to one of the 5 models listed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create the datasets <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We will be using NVIDIA's synthetic dataset on warehouse images based on the `kitti object detection dataset` format in this example. To find more details about kitti, please visit [here](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "DATA_DIR/train\n",
    "├── images/\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "\n",
    "DATA_DIR/val\n",
    "├── images\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "```\n",
    "The file name should be same for images and labels folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create a model experiment <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_arch = model_name.replace(\"-\",\"_\")\n",
    "model_id = subprocess.getoutput(f\"tao-client {model_name} model-create --network_arch {network_arch} --encryption_key tlt_encode \")\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'metadata.json')\n",
    "\n",
    "with open(metadata_path , \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata[\"train_datasets\"] = [train_dataset_id]\n",
    "metadata[\"eval_dataset\"] = eval_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Find pretrained model <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all pretrained models for the chosen network architecture\n",
    "pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "for ptm_metadata_path in glob.glob(pattern):\n",
    "  with open(ptm_metadata_path, 'r') as metadata_file:\n",
    "    ptm_metadata = json.load(metadata_file)\n",
    "    metadata_network_arch = ptm_metadata.get(\"network_arch\")\n",
    "    if metadata_network_arch == network_arch:\n",
    "      if \"encryption_key\" not in ptm_metadata.keys():\n",
    "        print(f'PTM Name: {ptm_metadata[\"name\"]}; PTM version: {ptm_metadata[\"version\"]}; NGC PATH: {ptm_metadata[\"ngc_path\"]}; Additional info: {ptm_metadata[\"additional_id_info\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of the available pretrained models listed in the OUTPUT of the previous cell you can choose a variant you wish\n",
    "# By default the PTM has been chosen as \"pretrained_object_detection:resnet18\" and the default train, evaluate spec files have parameters associated with resnet18\n",
    "# If you are changing the PTM to say pretrained_object_detection:resnet34 in the pretrained map variable below, \n",
    "    # then you have to change the associated spec parameters in the train spec in the \"Provide train spec section\"\n",
    "# For example you may need to change the parameter num_layers to 34 for pretrained_object_detection:resnet34\n",
    "# For more explanation into the spec dependency, view the documentation at https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different yolo versions\n",
    "# you are changing the number of layers to 34, then you have to make the appropriate change in the pretrained model name\n",
    "pretrained_map = {\"detectnet_v2\" : \"detectnet_v2:resnet18\",\n",
    "                  \"faster_rcnn\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v3\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4_tiny\": \"pretrained_object_detection:cspdarknet_tiny\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "ptm_id = None\n",
    "for ptm_metadata_path in glob.glob(pattern):\n",
    "  with open(ptm_metadata_path, 'r') as metadata_file:\n",
    "    ptm_metadata = json.load(metadata_file)\n",
    "    ngc_path = ptm_metadata.get(\"ngc_path\")\n",
    "    metadata_network_arch = ptm_metadata.get(\"network_arch\")\n",
    "    if metadata_network_arch == network_arch and ngc_path.endswith(pretrained_map[network_arch]):\n",
    "      ptm_id = ptm_metadata[\"id\"]\n",
    "      break\n",
    "\n",
    "metadata[\"ptm\"] = [ptm_id]\n",
    "print(ptm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View hyperparameters that are enabled for AutoML by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View default automl specs enabled\n",
    "! tao-client {model_name} model-automl-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/automl_defaults.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Set AutoML related configurations <a class=\"anchor\" id=\"head-10\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters: \n",
    "\n",
    "[DetectNet_V2](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id6), \n",
    "[FasterRCNN](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id24), \n",
    "[YOLO_V3](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id85), \n",
    "[YOLO_V4](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id92), \n",
    "[YOLO_V4_Tiny](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id94)\n",
    "\n",
    "View detailed info on TAO AutoML in the [TAO docs](https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html) and [TAO AutoML blog](https://developer.nvidia.com/blog/training-like-an-ai-pro-using-tao-automl/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose automl algorithm between \"Bayesian\" and \"HyperBand\".\n",
    "automl_algorithm=\"Bayesian\" # valid options: Bayesian/HyperBand\n",
    "\n",
    "#Don't change this, in future multiple metrics will be supported\n",
    "metric = \"map\"\n",
    "\n",
    "additional_automl_parameters = [] #Refer to parameter list mentioned in the above links and add any extra parameter in addition to the default enabled ones\n",
    "remove_default_automl_parameters = [] #Remove any hyperparameters that are enabled by default for AutoML\n",
    "\n",
    "metadata[\"automl_max_recommendations\"] = 10\n",
    "metadata[\"automl_algorithm\"] = automl_algorithm\n",
    "metadata[\"automl_enabled\"] = True\n",
    "metadata[\"metric\"] = metric\n",
    "metadata[\"automl_add_hyperparameters\"] = str(additional_automl_parameters)\n",
    "metadata[\"automl_remove_hyperparameters\"] = str(remove_default_automl_parameters)\n",
    "\n",
    "with open(metadata_path, \"w\") as metadata_file:\n",
    "    json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide train specs <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default train model specs\n",
    "! tao-client {model_name} model-train-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize train model specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'train.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "# Example for yolo_v4 (for each network the parameter key might be different)\n",
    "# Make any changes to specs param in the dictionary here\n",
    "# For example :\n",
    "specs[\"augmentation_config\"][\"output_width\"] = 960 # Setting to the Half-resolution, set this based on the dataset being used and the training/inference time tradeoff\n",
    "specs[\"augmentation_config\"][\"output_height\"] = 544 # Setting to the Half-resolution, set this based on the dataset being used and the training/inference time tradeoff\n",
    "\n",
    "if \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "    specs[\"dataset_config\"][\"image_extension\"] = \"jpg\"\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run AutoML train <a class=\"anchor\" id=\"head-12\"></a>\n",
    "AutoML run for YoloV4 takes ~18.5 hours to complete. The live ETA can be viewed in poll status cell\n",
    "\n",
    "For the default specs of the model, AutoML will yeild a model with mAP of around ~70% when compared to the ~64% baseline without AutoML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_job_id = subprocess.getoutput(f\"tao-client {model_name} model-train --id \" + model_id)\n",
    "print(train_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set poll_automl_stats to True if just want to see what's the time left, how many epochs are remaining etc.\n",
    "# Set poll_automl_stats to False if you want to skip stats and see the training logs instead. Training logs viewing are supported only for Bayesian\n",
    "\n",
    "poll_automl_stats = True\n",
    "if poll_automl_stats:\n",
    "    import time\n",
    "    from IPython.display import clear_output\n",
    "    stats_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, train_job_id, \"automl_metadata.json\")\n",
    "    controller_json_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, train_job_id, \"controller.json\")\n",
    "    while True:\n",
    "        time.sleep(15)\n",
    "        clear_output(wait=True)\n",
    "        if os.path.exists(stats_path):\n",
    "            try:\n",
    "                with open(stats_path , \"r\") as stats_file:\n",
    "                    stats_dict = json.load(stats_file)\n",
    "                print(json.dumps(stats_dict, indent=2))\n",
    "                if float(stats_dict[\"Number of epochs yet to start\"]) == 0.0:\n",
    "                    break\n",
    "            except (json.JSONDecodeError):\n",
    "                print(\"Stats computed are being written to file. Stats will be visible on screen in a few seconds\")\n",
    "else:\n",
    "    # Print the log file - supported only for bayesian (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    if automl_algorithm == \"Bayesian\":\n",
    "        logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id)\n",
    "        max_recommendations = metadata.get(\"automl_max_recommendations\",20)\n",
    "        for experiment_num in range(max_recommendations):\n",
    "            log_file = f\"{train_job_id}/experiment_{experiment_num}/log.txt\"\n",
    "            while True:\n",
    "                if os.path.exists(os.path.join(logs_dir, log_file)):\n",
    "                    break\n",
    "            print(f\"\\n\\nViewing experiment {experiment_num}\\n\\n\")\n",
    "            my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best model from AutoML <a class=\"anchor\" id=\"head-13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config and the weights of the best configuration are present at best_model folder\n",
    "# Takes a few seconds to copy the original automl experiment to best_model folder\n",
    "\n",
    "# Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
    "\n",
    "!python3 -m pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "automl_job_dir = f\"{home}/shared/users/{os.environ['USER']}/models/{model_id}/{train_job_id}\"\n",
    "best_model_path =  f\"{automl_job_dir}/best_model\"\n",
    "\n",
    "while True:\n",
    "    if os.path.exists(best_model_path) and len(os.listdir(best_model_path)) > 0 and os.path.exists(f\"{best_model_path}/controller.json\"):\n",
    "        #List the binary model file\n",
    "        print(\"\\nCheckpoints for the best performing experiment\")\n",
    "        if os.path.exists(best_model_path+\"/weights\") and len(os.listdir(best_model_path+\"/weights\")) > 0:\n",
    "            print(f\"Folder: {best_model_path}/weights\")\n",
    "            print(\"Files:\", os.listdir(best_model_path+\"/weights\"))\n",
    "        else:\n",
    "            print(f\"Folder: {best_model_path}\")\n",
    "            print(\"Files:\", os.listdir(best_model_path))\n",
    "\n",
    "        experiment_artifacts = json.load(open(f\"{best_model_path}/controller.json\",\"r\"))\n",
    "        data_frame = pd.DataFrame(experiment_artifacts)\n",
    "        # Print experiment id/number and the corresponding result\n",
    "        print(\"\\nResults of all experiments\")\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "            print(data_frame[[\"id\",\"result\"]])\n",
    "\n",
    "        print(\"\\nConfig/Spec file for the best performing experiment (recommendation_id.kitti with the maximum result value in the dataframe)\")\n",
    "        # List the recommendation config file of the best performing checkpoint(recommendation_id.kitti with the maximum result value in the dataframe)\n",
    "        !ls {best_model_path}/*.kitti \n",
    "            \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete experiment (Optional) <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! rm -rf ~/shared/users/{os.environ['USER']}/models/{model_id}\n",
    "# ! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete datasets (Optional) <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}\n",
    "# ! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}\n",
    "# ! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we are at the end of the Launchpad workflow.\n",
    "\n",
    "We started off by a training a yolo-v4 model, then optimizing it for better inference performance,\n",
    "\n",
    "And finally we ran an AutoML experiment on yolo-v4 where we could see an improvement of around 5% <br>in accuracy metrics when compared to the baseline model we trained initially\n",
    "\n",
    "You can try several other object detection models, or other domains like classification, segmentation <br>\n",
    "or even purpose built models like License Plate recognition on your machine with the TAO getting started guide from [NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/resources/tao-getting-started/files)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
